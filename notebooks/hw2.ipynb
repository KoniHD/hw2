{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoniHD/hw2/blob/main/notebooks/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ps_Sgfwa2jw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCUK1XgCa2jz"
      },
      "source": [
        "## Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSDhZpmd9iYR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2mAudited \u001b[1m100 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"../pyproject.toml\"):\n",
        "    print(\"Repo doesn't exist yet. Cloning from github ...\")\n",
        "    !git clone https://github.com/KoniHD/hw2.git\n",
        "    os.chdir(\"hw2\")\n",
        "\n",
        "!uv add -r requirements.txt\n",
        "!uv sync --active --package hw2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Di6-eua2jy"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rM1U4K1_a2jy"
      },
      "outputs": [],
      "source": [
        "# Fetch data\n",
        "!mkdir -p data\n",
        "!wget -q -P data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
        "!unzip -q -n data/train-test-data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirgyzOY9soh"
      },
      "source": [
        "## Imports libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL3J8GNs8zZS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/programmer/Programming/University/Semester_Cal/hw2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from lightning.pytorch import Trainer, seed_everything\n",
        "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
        "\n",
        "from data.custom_transforms import (\n",
        "    Rescale,\n",
        "    RandomCrop,\n",
        "    Normalize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "from data.facial_keypoints_dataset import FacialKeypointsDataset\n",
        "\n",
        "from models.simple_cnn import Simple_CNN\n",
        "from keypoint_task import KeypointDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    # Data\n",
        "    \"batch_size\": 16,\n",
        "    \"img_size\": 224,\n",
        "    # Model\n",
        "    \"out_dim\": 136,\n",
        "    \"activation\": \"relu\",\n",
        "    \"droupout_rate\": 0.3,\n",
        "    # Training\n",
        "    \"lr\": 4e-3,\n",
        "    \"max_epochs\": 30,\n",
        "    \"criterion\": \"mse\",\n",
        "    \"seed\": 42\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZxP8lka2j1"
      },
      "source": [
        "## Load Data and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwfRjCZra2j2"
      },
      "outputs": [],
      "source": [
        "seed_everything(42, workers=True)   # Try to create deterministic results\n",
        "\n",
        "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
        "# order matters! i.e. rescaling should come before a smaller crop\n",
        "data_transform = transforms.Compose(\n",
        "    [Rescale(250), RandomCrop(config[\"img_size\"]), Normalize(), ToTensor()]\n",
        ")\n",
        "\n",
        "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
        "training_data_dir = os.path.join(\"data\", \"training\")\n",
        "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
        "test_data_dir = os.path.join(\"data\", \"test\")\n",
        "\n",
        "\n",
        "# create the transformed dataset\n",
        "transformed_dataset = FacialKeypointsDataset(\n",
        "    csv_file=training_keypoints_csv_path,\n",
        "    root_dir=training_data_dir,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "# load training data in batches\n",
        "train_loader = DataLoader(\n",
        "    transformed_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "# creating the test dataset\n",
        "test_dataset = FacialKeypointsDataset(\n",
        "    csv_file=test_keypoints_csv_path,\n",
        "    root_dir=test_data_dir,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "# loading test data in batches\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "    sample = data\n",
        "    image = sample['image'][0]\n",
        "    keypoints = sample['keypoints'][0]\n",
        "    _, h, w = image.shape\n",
        "    # plot the image black and white\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
        "    plt.scatter(keypoints[:, 0]*(w/2)+(w/2), keypoints[:, 1]*(h/2)+(h/2), c='r', s=20)\n",
        "    plt.show()\n",
        "    print(f\"Image min/max:   {image.min():.4f} / {image.max():.4f}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8_w-xZmPB8a"
      },
      "source": [
        "# Data Exploration & Sanity Checks\n",
        "\n",
        "Observe basic dataset characteristics and sanity check via **model overfitting**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmhi2zWAPIKP"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n\\n===Metrics of first batch===\")\n",
        "batch = next(iter(train_loader))\n",
        "images, keypoints = batch['image'], batch['keypoints']\n",
        "\n",
        "print(f\"Image shape:\\t\\t{images.shape}\")\n",
        "print(f\"Image min/max:\\t\\t{images.min():.4f} / {images.max():.4f}\\t\\twithin [-1, 1]: {(-0 <= images.min().round(decimals=1) and images.max().round(decimals=1) <= 1)}\")\n",
        "print(f\"Keypoints min/max:\\t{keypoints.min():.4f} / {keypoints.max():.4f}\\twithin [-1, 1]: {(-1 <= keypoints.min().round(decimals=1) and keypoints.max().round(decimals=1) <= 1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LABF1vEIa2j3"
      },
      "source": [
        "# Training\n",
        "\n",
        "Define the lightning wrapper for every model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "simple_cnn = Simple_CNN(out_dim=config[\"out_dim\"], activation=config[\"activation\"], dropout=config[\"droupout_rate\"])\n",
        "keypoint_task = KeypointDetection(model=simple_cnn, lr=config[\"lr\"], criterion=config[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfcIo2Evcj0k"
      },
      "source": [
        "## Testing overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbvaUkvUcm3S"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "print(f\"Running on device={device}\")\n",
        "# Simple train setup\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "model.train()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Overfitting loop\n",
        "batch = next(iter(train_loader))\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    images, keypoints = batch['image'].to(device), batch['keypoints'].to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, keypoints.view(keypoints.shape[0], -1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}\\t|\\tLoss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_aqeW8chGh-"
      },
      "source": [
        "Visualize overfitting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ9aXOqUehnU"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "\n",
        "outputs = outputs.view(-1, 68, 2).cpu()\n",
        "images_cpu = images.cpu()\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    _, h, w = images_cpu[i].shape\n",
        "    ax.imshow(images_cpu[i].numpy().transpose(1, 2, 0), cmap='gray')\n",
        "    ax.scatter(outputs[i, :, 0] * (w/2) + (w/2), outputs[i, :, 1] * (h/2) + (h/2), c='r', s=10)\n",
        "    ax.scatter(keypoints[i, :, 0].cpu() * (w/2) + (w/2), keypoints[i, :, 1].cpu() * (h/2) + (h/2), c='g', s=10)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Red=Predicted, Green=Ground Truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrZ6RSxAhWdp"
      },
      "source": [
        "## Real training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SuJ3fC667--P"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "print(f\"Running on device={device}\")\n",
        "\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device, epoch: int):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Train Epoch: {epoch+1}\")\n",
        "    for batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        images = batch['image'].to(device)\n",
        "        keypoints = batch['keypoints'].to(device)\n",
        "        predictated_keypoints = model(images)\n",
        "        loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, device, epoch: int):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f\"Val Epoch: {epoch+1}\")\n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(device)\n",
        "            keypoints = batch['keypoints'].to(device)\n",
        "            predictated_keypoints = model(images)\n",
        "            loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(val_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device, epoch)\n",
        "    val_loss = validate(model, test_loader, criterion, device, epoch)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z75HW8OkhcnD"
      },
      "source": [
        "## Training using PyTorch Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXzwnkK1h1_o"
      },
      "outputs": [],
      "source": [
        "# Create a fresh model for Lightning Module\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "keypoint_task = KeypointDetection(model, criterion=\"mse\")\n",
        "\n",
        "# Define trainer and train model\n",
        "trainer = Trainer(max_epochs=10,\n",
        "                  accelerator='auto',\n",
        "                  deterministic='warn',\n",
        "                  default_root_dir=os.path.join(os.getcwd(), 'exp'))\n",
        "trainer.fit(keypoint_task, train_dataloaders=train_loader, val_dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ld5MBWE7wp8c"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir exp/lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDySf5mQa2j4"
      },
      "source": [
        "## Part 1: Direct Coordinate Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFFF-3WDa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Training a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFAw_LKQa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtHhRjaa2j5"
      },
      "source": [
        "## Part 2: Transfer Learning for Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzFlbK2a2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Pretrained ResNet backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k3E1xCEa2j6"
      },
      "outputs": [],
      "source": [
        "# TODO: Advanced pretrained models (DINO, MAE, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rP0fd7Ea2j7"
      },
      "source": [
        "## Part 3: Heatmap-based Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfszKqgaa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Heatmap synthesis and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmoklOYxa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of heatmap prediction"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
