{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoniHD/hw2/blob/main/notebooks/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ps_Sgfwa2jw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCUK1XgCa2jz"
      },
      "source": [
        "## Clone Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSDhZpmd9iYR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"pyproject.toml\"):\n",
        "    print(\"Repo doesn't exist yet. Cloning from github ...\")\n",
        "    !git clone --quiet --depth 1 https://github.com/KoniHD/hw2.git\n",
        "    os.chdir(\"hw2\")\n",
        "\n",
        "!uv pip install -r --quiet requirements.txt --system\n",
        "os.chdir(\"..\")\n",
        "os.kill(os.getpid(), 9)  # Restart kernel to make modules available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Di6-eua2jy"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rM1U4K1_a2jy"
      },
      "outputs": [],
      "source": [
        "# Fetch data\n",
        "!mkdir -p data\n",
        "!wget -q -P data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
        "!unzip -q -n data/train-test-data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirgyzOY9soh"
      },
      "source": [
        "## Imports libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL3J8GNs8zZS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from lightning.pytorch import Trainer, seed_everything\n",
        "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "from data.custom_transforms import (\n",
        "    Rescale,\n",
        "    RandomCrop,\n",
        "    Normalize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "from data.facial_keypoints_dataset import FacialKeypointsDataset\n",
        "\n",
        "from models.simple_cnn import Simple_CNN\n",
        "from keypoint_task import KeypointDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GicqPL44y7qW"
      },
      "source": [
        "## Set Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UVi7aUiy7qZ"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    # Data\n",
        "    \"batch_size\": 16,\n",
        "    \"img_size\": 224,\n",
        "    # Model\n",
        "    \"out_dim\": 136,\n",
        "    \"activation\": \"relu\",\n",
        "    \"dropout_rate\": 0.3,\n",
        "    \"batch_norm\": True,\n",
        "    # Training\n",
        "    \"lr\": 4e-3,\n",
        "    \"max_epochs\": 30,\n",
        "    \"criterion\": \"mse\",\n",
        "    \"random_seed\": 42,\n",
        "    \"patience\": 5,\n",
        "    \"optimizer\": \"adam\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZxP8lka2j1"
      },
      "source": [
        "## Load Data and visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwfRjCZra2j2"
      },
      "outputs": [],
      "source": [
        "seed_everything(\n",
        "    config[\"random_seed\"], workers=True\n",
        ")  # Try to create deterministic results\n",
        "\n",
        "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
        "# order matters! i.e. rescaling should come before a smaller crop\n",
        "data_transform = transforms.Compose(\n",
        "    [Rescale(250), RandomCrop(config[\"img_size\"]), Normalize(), ToTensor()]\n",
        ")\n",
        "\n",
        "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
        "training_data_dir = os.path.join(\"data\", \"training\")\n",
        "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
        "test_data_dir = os.path.join(\"data\", \"test\")\n",
        "\n",
        "\n",
        "# create the transformed dataset\n",
        "transformed_dataset = FacialKeypointsDataset(\n",
        "    csv_file=training_keypoints_csv_path,\n",
        "    root_dir=training_data_dir,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "# load training data in batches\n",
        "train_loader = DataLoader(\n",
        "    transformed_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "# creating the test dataset\n",
        "test_dataset = FacialKeypointsDataset(\n",
        "    csv_file=test_keypoints_csv_path, root_dir=test_data_dir, transform=data_transform\n",
        ")\n",
        "\n",
        "# loading test data in batches\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "    sample = data\n",
        "    image = sample[\"image\"][0]\n",
        "    keypoints = sample[\"keypoints\"][0]\n",
        "    _, h, w = image.shape\n",
        "    # plot the image black and white\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap=\"gray\")\n",
        "    plt.scatter(\n",
        "        keypoints[:, 0] * (w / 2) + (w / 2),\n",
        "        keypoints[:, 1] * (h / 2) + (h / 2),\n",
        "        c=\"r\",\n",
        "        s=20,\n",
        "    )\n",
        "    plt.show()\n",
        "    print(f\"Image min/max:   {image.min():.4f} / {image.max():.4f}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8_w-xZmPB8a"
      },
      "source": [
        "# Data Exploration & Sanity Checks\n",
        "\n",
        "Observe basic dataset characteristics and sanity check via **model overfitting**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmhi2zWAPIKP"
      },
      "outputs": [],
      "source": [
        "print(f\"===Metrics of first batch===\")\n",
        "batch = next(iter(train_loader))\n",
        "images, keypoints = batch[\"image\"], batch[\"keypoints\"]\n",
        "\n",
        "print(f\"Image shape:\\t\\t{images.shape}\")\n",
        "print(\n",
        "    f\"Image min/max:\\t\\t{images.min():.4f} / {images.max():.4f}\\t\\twithin [0, 1]: {(-0 <= images.min().round(decimals=1) and images.max().round(decimals=1) <= 1)}\"\n",
        ")\n",
        "print(\n",
        "    f\"Keypoints min/max:\\t{keypoints.min():.4f} / {keypoints.max():.4f}\\twithin [-1, 1]: {(-1 <= keypoints.min().round(decimals=1) and keypoints.max().round(decimals=1) <= 1)}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Direct Coordinate Regression\n",
        "\n",
        "### Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSjMHWkcy7qq"
      },
      "outputs": [],
      "source": [
        "default_exp_dir = \"exp/simple_cnn/\"\n",
        "\n",
        "# Model\n",
        "simple_cnn = Simple_CNN(\n",
        "    out_dim=config[\"out_dim\"],\n",
        "    activation=config[\"activation\"],\n",
        "    dropout=0.0,\n",
        "    batch_norm=False,\n",
        ")\n",
        "\n",
        "# Lightning Wrapper\n",
        "keypoint_task = KeypointDetection(\n",
        "    model=simple_cnn,\n",
        "    lr=config[\"lr\"],\n",
        "    criterion=config[\"criterion\"],\n",
        "    patience=config[\"patience\"],\n",
        "    optimizer=config[\"optimizer\"],\n",
        "    activation=config[\"activation\"],\n",
        "    drouput=0.0,\n",
        "    batch_norm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=200,\n",
        "    accelerator=\"auto\",\n",
        "    deterministic=\"warn\",\n",
        "    logger=False,\n",
        "    default_root_dir=default_exp_dir,\n",
        "    detect_anomaly=True,\n",
        "    overfit_batches=1,\n",
        "    enable_autolog_hparams=False,\n",
        "    enable_checkpointing=False,\n",
        ")\n",
        "trainer.fit(keypoint_task, train_dataloaders=train_loader)\n",
        "\n",
        "metrics = trainer.callback_metrics\n",
        "print(f\"\\n\\n=============\\nFinal train loss: {metrics['train_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_aqeW8chGh-"
      },
      "source": [
        "Visualize overfitting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ9aXOqUehnU"
      },
      "outputs": [],
      "source": [
        "keypoint_task.eval()\n",
        "with torch.inference_mode():\n",
        "    outputs = keypoint_task.forward(images)\n",
        "\n",
        "outputs = outputs.view(-1, 68, 2).cpu()\n",
        "images_cpu = images.cpu()\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    _, h, w = images_cpu[i].shape\n",
        "    ax.imshow(images_cpu[i].numpy().transpose(1, 2, 0), cmap=\"gray\")\n",
        "    ax.scatter(\n",
        "        outputs[i, :, 0] * (w / 2) + (w / 2),\n",
        "        outputs[i, :, 1] * (h / 2) + (h / 2),\n",
        "        c=\"r\",\n",
        "        s=10,\n",
        "    )\n",
        "    ax.scatter(\n",
        "        keypoints[i, :, 0].cpu() * (w / 2) + (w / 2),\n",
        "        keypoints[i, :, 1].cpu() * (h / 2) + (h / 2),\n",
        "        c=\"g\",\n",
        "        s=10,\n",
        "    )\n",
        "    ax.axis(\"off\")\n",
        "plt.suptitle(\"Red=Predicted, Green=Ground Truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrZ6RSxAhWdp"
      },
      "source": [
        "## Real training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SuJ3fC667--P"
      },
      "outputs": [],
      "source": [
        "version = 0\n",
        "\n",
        "simple_cnn = Simple_CNN(\n",
        "    out_dim=config[\"out_dim\"],\n",
        "    activation=config[\"activation\"],\n",
        "    dropout=config[\"dropout_rate\"],\n",
        "    batch_norm=config[\"batch_norm\"],\n",
        ")\n",
        "\n",
        "simple_cnn = torch.compile(simple_cnn, mode=\"max-autotune\")\n",
        "\n",
        "keypoint_task = KeypointDetection(\n",
        "    model=simple_cnn,\n",
        "    lr=config[\"lr\"],\n",
        "    criterion=config[\"criterion\"],\n",
        "    patience=config[\"patience\"],\n",
        "    optimizer=config[\"optimizer\"],\n",
        "    activation=config[\"activation\"],\n",
        "    drouput=config[\"dropout_rate\"],\n",
        "    batch_norm=config[\"batch_norm\"],\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=default_exp_dir + f\"version_{version}\",\n",
        "    filename=\"simple-cnn\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_top_k=1,\n",
        "    save_last=True,\n",
        "    save_weights_only=True,\n",
        "    enable_version_counter=True,\n",
        ")\n",
        "\n",
        "earlystopping_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=config[\"patience\"], mode=\"min\", verbose=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    accelerator=\"auto\",\n",
        "    logger=[\n",
        "        TensorBoardLogger(\n",
        "            default_exp_dir,\n",
        "            name=\"\",\n",
        "            version=f\"version_{version}\",\n",
        "            log_graph=True,\n",
        "            default_hp_metric=False,\n",
        "        ),\n",
        "        CSVLogger(default_exp_dir, name=\"\", version=f\"version_{version}\"),\n",
        "    ],\n",
        "    max_epochs=config[\"max_epochs\"],\n",
        "    callbacks=[checkpoint_callback, earlystopping_callback],\n",
        "    deterministic=\"warn\",\n",
        "    default_root_dir=default_exp_dir,\n",
        "    num_sanity_val_steps=0,\n",
        "    enable_checkpointing=True,\n",
        "    enable_autolog_hparams=False,\n",
        ")\n",
        "\n",
        "trainer.fit(keypoint_task, train_dataloaders=train_loader, val_dataloaders=test_loader)\n",
        "\n",
        "keypoint_task = KeypointDetection.load_from_checkpoint(\n",
        "    checkpoint_callback.best_model_path, weights_only=True, model=simple_cnn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc-_BYTYy7qw"
      },
      "source": [
        "### Visualize Loss Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkoZiza4y7qx"
      },
      "outputs": [],
      "source": [
        "metrics = pd.read_csv(default_exp_dir + f\"version_{version}/metrics.csv\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "metrics[[\"epoch\", \"train_loss\"]].dropna().plot(x=\"epoch\", ax=ax, label=\"Train Loss\")\n",
        "metrics[[\"epoch\", \"val_loss\"]].dropna().plot(x=\"epoch\", ax=ax, label=\"Val Loss\")\n",
        "ax.set_xlabel(\"Epoch\")\n",
        "ax.set_ylabel(\"MSE Loss\")\n",
        "ax.set_title(f\"Part 1: Simple CNN Training Curve Version {version}\")\n",
        "ax.set_xlim(left=0.0)\n",
        "ax.set_ylim(bottom=0.0)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z75HW8OkhcnD"
      },
      "source": [
        "### Visualize using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ld5MBWE7wp8c"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir {default_exp_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Optional:** Save model weights to huggingface for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTaGYyrB-nzD"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "model_to_save = getattr(simple_cnn, \"_orig_mod\", simple_cnn)\n",
        "model_to_save.push_to_hub(\"username/simple-cnn-keypoints\")\n",
        "\n",
        "model_to_save.push_to_hub(\n",
        "    \"KoniHD/Simple_CNN\",\n",
        "    config=config,\n",
        "    commit_message=f\"Training run version: {version}\",\n",
        "    private=True,\n",
        "    token=hf_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFFF-3WDa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Training a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFAw_LKQa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtHhRjaa2j5"
      },
      "source": [
        "## Part 2: Transfer Learning for Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzFlbK2a2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Pretrained ResNet backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k3E1xCEa2j6"
      },
      "outputs": [],
      "source": [
        "# TODO: Advanced pretrained models (DINO, MAE, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rP0fd7Ea2j7"
      },
      "source": [
        "## Part 3: Heatmap-based Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfszKqgaa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Heatmap synthesis and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmoklOYxa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of heatmap prediction"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
