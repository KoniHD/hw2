{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoniHD/hw2/blob/main/src/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ps_Sgfwa2jw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Di6-eua2jy"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rM1U4K1_a2jy"
      },
      "outputs": [],
      "source": [
        "# Fetch data\n",
        "!mkdir data\n",
        "!wget -P data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
        "!unzip -n data/train-test-data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCUK1XgCa2jz"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "Download the model code."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIXME: Necessary but not nice. Do imports better!\n",
        "!git clone https://github.com/KoniHD/hw2.git\n",
        "!mv hw2/src/* .\n",
        "!rm -rf hw2 __init__.py hw2.ipynb"
      ],
      "metadata": {
        "id": "hSDhZpmd9iYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add necessary dependencies."
      ],
      "metadata": {
        "id": "rorJvycT9oZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e4ipQyta2j0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# No need if you are using colab\n",
        "\n",
        "# !pip install matplotlib~=3.5.2\n",
        "# !pip install scikit-image==0.19.2\n",
        "# !pip install torch~=1.8.1\n",
        "# !pip install torchvision~=0.9.1\n",
        "# !pip install numpy~=1.21.6\n",
        "# !pip install pillow~=9.1.1\n",
        "# !pip install tqdm~=4.64.0\n",
        "# !pip install jupyter==1.0.0\n",
        "# !pip install opencv-python==4.6.0.66\n",
        "# !pip install pandas==1.3.5\n",
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries and configure enviromnet."
      ],
      "metadata": {
        "id": "pirgyzOY9soh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "\n",
        "from lightning.pytorch import Trainer, seed_everything\n",
        "seed_everything(42, workers=True)   # Try to create deterministic results\n",
        "\n",
        "# the transforms we defined in Notebook 1 are in the helper file `custom_transforms.py`\n",
        "from custom_transforms import (\n",
        "    Rescale,\n",
        "    RandomCrop,\n",
        "    NormalizeOriginal,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "# the dataset we created in Notebook 1\n",
        "from facial_keypoints_dataset import FacialKeypointsDataset\n",
        "\n",
        "from model import Simple_CNN\n",
        "from keypoint_task import KeypointDetection"
      ],
      "metadata": {
        "id": "lL3J8GNs8zZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZxP8lka2j1"
      },
      "source": [
        "## Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwfRjCZra2j2"
      },
      "outputs": [],
      "source": [
        "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
        "# order matters! i.e. rescaling should come before a smaller crop\n",
        "data_transform = transforms.Compose(\n",
        "    [Rescale(250), RandomCrop(224), NormalizeOriginal(), ToTensor()]\n",
        ")\n",
        "\n",
        "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
        "training_data_dir = os.path.join(\"data\", \"training\")\n",
        "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
        "test_data_dir = os.path.join(\"data\", \"test\")\n",
        "\n",
        "\n",
        "# create the transformed dataset\n",
        "transformed_dataset = FacialKeypointsDataset(\n",
        "    csv_file=training_keypoints_csv_path,\n",
        "    root_dir=training_data_dir,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "# load training data in batches\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(\n",
        "    transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "# creating the test dataset\n",
        "test_dataset = FacialKeypointsDataset(\n",
        "    csv_file=test_keypoints_csv_path,\n",
        "    root_dir=test_data_dir,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "# loading test data in batches\n",
        "batch_size = 16\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "    sample = data\n",
        "    image = sample['image'][0]\n",
        "    keypoints = sample['keypoints'][0]\n",
        "    # plot the image black and white\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
        "    plt.scatter(keypoints[:, 0]*50+100, keypoints[:, 1]*50+100, c='r', s=20)\n",
        "    plt.show()\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LABF1vEIa2j3"
      },
      "source": [
        "# Training\n",
        "This is a conventional test loop. Below I am attempting to wrap training and inference in PyTorch Lightning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "print(f\"Running on device={device}\")\n",
        "\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device, epoch: int):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Train Epoch: {epoch}\")\n",
        "    for batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        images = batch['image'].to(device)\n",
        "        keypoints = batch['keypoints'].to(device)\n",
        "        predictated_keypoints = model(images)\n",
        "        loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, device, epoch: int):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f\"Val Epoch: {epoch}\")\n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(device)\n",
        "            keypoints = batch['keypoints'].to(device)\n",
        "            predictated_keypoints = model(images)\n",
        "            loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(val_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device, epoch)\n",
        "    val_loss = validate(model, test_loader, criterion, device, epoch)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}')"
      ],
      "metadata": {
        "id": "SuJ3fC667--P",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fresh model for Lightning Module\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "keypoint_task = KeypointDetection(model, criterion=nn.MSELoss())\n",
        "\n",
        "# Define trainer and train model\n",
        "trainer = Trainer(max_epochs=10,\n",
        "                  accelerator='auto',\n",
        "                  deterministic='warn',\n",
        "                  default_root_dir=os.path.join(os.getcwd(), 'exp'))\n",
        "trainer.fit(keypoint_task, train_dataloaders=train_loader, val_dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "NXzwnkK1h1_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir exp/lightning_logs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ld5MBWE7wp8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDySf5mQa2j4"
      },
      "source": [
        "## Part 1: Direct Coordinate Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFFF-3WDa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Training a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFAw_LKQa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtHhRjaa2j5"
      },
      "source": [
        "## Part 2: Transfer Learning for Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzFlbK2a2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Pretrained ResNet backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k3E1xCEa2j6"
      },
      "outputs": [],
      "source": [
        "# TODO: Advanced pretrained models (DINO, MAE, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rP0fd7Ea2j7"
      },
      "source": [
        "## Part 3: Heatmap-based Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfszKqgaa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Heatmap synthesis and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmoklOYxa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of heatmap prediction"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}