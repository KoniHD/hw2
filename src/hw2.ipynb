{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ps_Sgfwa2jw"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Di6-eua2jy"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rM1U4K1_a2jy"
      },
      "outputs": [],
      "source": [
        "# Fetch data\n",
        "!mkdir data\n",
        "!wget -P data/ https://s3.amazonaws.com/video.udacity-data.com/topher/2018/May/5aea1b91_train-test-data/train-test-data.zip\n",
        "!unzip -q -n data/train-test-data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCUK1XgCa2jz"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "Download the model code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSDhZpmd9iYR"
      },
      "outputs": [],
      "source": [
        "# FIXME: Necessary but not nice. Do imports better!\n",
        "!git clone https://github.com/KoniHD/hw2.git\n",
        "!mv hw2/src/* .\n",
        "!rm -rf hw2 __init__.py hw2.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rorJvycT9oZK"
      },
      "source": [
        "Add necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8e4ipQyta2j0"
      },
      "outputs": [],
      "source": [
        "# No need if you are using colab\n",
        "\n",
        "# !pip install matplotlib~=3.5.2\n",
        "# !pip install torch~=1.8.1\n",
        "# !pip install torchvision~=0.9.1\n",
        "# !pip install numpy~=1.21.6\n",
        "# !pip install pillow~=9.1.1\n",
        "# !pip install tqdm~=4.64.0\n",
        "# !pip install jupyter==1.0.0\n",
        "# !pip install opencv-python==4.6.0.66\n",
        "# !pip install pandas==1.3.5\n",
        "!pip install -q lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pirgyzOY9soh"
      },
      "source": [
        "Import required libraries and configure enviromnet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL3J8GNs8zZS"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "\n",
        "from lightning.pytorch import Trainer, seed_everything\n",
        "seed_everything(42, workers=True)   # Try to create deterministic results\n",
        "\n",
        "# the transforms we defined in Notebook 1 are in the helper file `custom_transforms.py`\n",
        "from custom_transforms import (\n",
        "    Rescale,\n",
        "    RandomCrop,\n",
        "    Normalize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "# the dataset we created in Notebook 1\n",
        "from facial_keypoints_dataset import FacialKeypointsDataset\n",
        "\n",
        "from model import Simple_CNN\n",
        "from keypoint_task import KeypointDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbZxP8lka2j1"
      },
      "source": [
        "## Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwfRjCZra2j2"
      },
      "outputs": [],
      "source": [
        "# defining the data_transform using transforms.Compose([all tx's, . , .])\n",
        "# order matters! i.e. rescaling should come before a smaller crop\n",
        "data_transform = transforms.Compose(\n",
        "    [Rescale(250), RandomCrop(224), Normalize(), ToTensor()]\n",
        ")\n",
        "\n",
        "training_keypoints_csv_path = os.path.join(\"data\", \"training_frames_keypoints.csv\")\n",
        "training_data_dir = os.path.join(\"data\", \"training\")\n",
        "test_keypoints_csv_path = os.path.join(\"data\", \"test_frames_keypoints.csv\")\n",
        "test_data_dir = os.path.join(\"data\", \"test\")\n",
        "\n",
        "\n",
        "# create the transformed dataset\n",
        "transformed_dataset = FacialKeypointsDataset(\n",
        "    csv_file=training_keypoints_csv_path,\n",
        "    root_dir=training_data_dir,\n",
        "    transform=data_transform,\n",
        ")\n",
        "\n",
        "# load training data in batches\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(\n",
        "    transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "# creating the test dataset\n",
        "test_dataset = FacialKeypointsDataset(\n",
        "    csv_file=test_keypoints_csv_path,\n",
        "    root_dir=test_data_dir,\n",
        "    transform=data_transform\n",
        ")\n",
        "\n",
        "# loading test data in batches\n",
        "batch_size = 16\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "    sample = data\n",
        "    image = sample['image'][0]\n",
        "    keypoints = sample['keypoints'][0]\n",
        "    _, h, w = image.shape\n",
        "    # plot the image black and white\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0), cmap='gray')\n",
        "    plt.scatter(keypoints[:, 0]*(w/2)+(w/2), keypoints[:, 1]*(h/2)+(h/2), c='r', s=20)\n",
        "    plt.show()\n",
        "    print(f\"Image min/max:   {image.min():.4f} / {image.max():.4f}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8_w-xZmPB8a"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmhi2zWAPIKP"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n\\n===Metrics of first batch===\")\n",
        "batch = next(iter(train_loader))\n",
        "images, keypoints = batch['image'], batch['keypoints']\n",
        "\n",
        "print(f\"Image shape:\\t\\t{images.shape}\")\n",
        "print(f\"Image min/max:\\t\\t{images.min():.4f} / {images.max():.4f}\\t\\twithin [-1, 1]: {(-0 <= images.min().round(decimals=1) and images.max().round(decimals=1) <= 1)}\")\n",
        "print(f\"Keypoints min/max:\\t{keypoints.min():.4f} / {keypoints.max():.4f}\\twithin [-1, 1]: {(-1 <= keypoints.min().round(decimals=1) and keypoints.max().round(decimals=1) <= 1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LABF1vEIa2j3"
      },
      "source": [
        "# Training\n",
        "This is a conventional test loop. Below I am attempting to wrap training and inference in PyTorch Lightning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing overfitting"
      ],
      "metadata": {
        "id": "OfcIo2Evcj0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "print(f\"Running on device={device}\")\n",
        "# Simple train setup\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "model.to(device)\n",
        "model = torch.compile(model)\n",
        "model.train()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Overfitting loop\n",
        "batch = next(iter(train_loader))\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    images, keypoints = batch['image'].to(device), batch['keypoints'].to(device)\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, keypoints.view(keypoints.shape[0], -1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}\\t|\\tLoss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "NbvaUkvUcm3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize overfitting results"
      ],
      "metadata": {
        "id": "P_aqeW8chGh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "\n",
        "outputs = outputs.view(-1, 68, 2).cpu()\n",
        "images_cpu = images.cpu()\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    _, h, w = images_cpu[i].shape\n",
        "    ax.imshow(images_cpu[i].numpy().transpose(1, 2, 0), cmap='gray')\n",
        "    ax.scatter(outputs[i, :, 0] * (w/2) + (w/2), outputs[i, :, 1] * (h/2) + (h/2), c='r', s=10)\n",
        "    ax.scatter(keypoints[i, :, 0].cpu() * (w/2) + (w/2), keypoints[i, :, 1].cpu() * (h/2) + (h/2), c='g', s=10)\n",
        "    ax.axis('off')\n",
        "plt.suptitle(\"Red=Predicted, Green=Ground Truth\")"
      ],
      "metadata": {
        "id": "jJ9aXOqUehnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real training loop"
      ],
      "metadata": {
        "id": "QrZ6RSxAhWdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SuJ3fC667--P"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda:0\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")\n",
        "print(f\"Running on device={device}\")\n",
        "\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "model = torch.compile(model)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device, epoch: int):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Train Epoch: {epoch}\")\n",
        "    for batch in pbar:\n",
        "        optimizer.zero_grad()\n",
        "        images = batch['image'].to(device)\n",
        "        keypoints = batch['keypoints'].to(device)\n",
        "        predictated_keypoints = model(images)\n",
        "        loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, device, epoch: int):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc=f\"Val Epoch: {epoch}\")\n",
        "        for batch in pbar:\n",
        "            images = batch['image'].to(device)\n",
        "            keypoints = batch['keypoints'].to(device)\n",
        "            predictated_keypoints = model(images)\n",
        "            loss = criterion(predictated_keypoints, keypoints.view(keypoints.size(0), -1))\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return running_loss / len(val_loader)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device, epoch)\n",
        "    val_loss = validate(model, test_loader, criterion, device, epoch)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training using PyTorch Lightning"
      ],
      "metadata": {
        "id": "z75HW8OkhcnD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXzwnkK1h1_o"
      },
      "outputs": [],
      "source": [
        "# Create a fresh model for Lightning Module\n",
        "model = Simple_CNN(out_dim=136, activation=nn.ReLU)\n",
        "keypoint_task = KeypointDetection(model, criterion=nn.MSELoss())\n",
        "\n",
        "# Define trainer and train model\n",
        "trainer = Trainer(max_epochs=10,\n",
        "                  accelerator='auto',\n",
        "                  deterministic='warn',\n",
        "                  default_root_dir=os.path.join(os.getcwd(), 'exp'))\n",
        "trainer.fit(keypoint_task, train_dataloaders=train_loader, val_dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ld5MBWE7wp8c"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir exp/lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDySf5mQa2j4"
      },
      "source": [
        "## Part 1: Direct Coordinate Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFFF-3WDa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Training a simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFAw_LKQa2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtHhRjaa2j5"
      },
      "source": [
        "## Part 2: Transfer Learning for Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzFlbK2a2j5"
      },
      "outputs": [],
      "source": [
        "# TODO: Pretrained ResNet backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k3E1xCEa2j6"
      },
      "outputs": [],
      "source": [
        "# TODO: Advanced pretrained models (DINO, MAE, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rP0fd7Ea2j7"
      },
      "source": [
        "## Part 3: Heatmap-based Keypoint Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfszKqgaa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Heatmap synthesis and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmoklOYxa2j7"
      },
      "outputs": [],
      "source": [
        "# TODO: Visualization of heatmap prediction"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}